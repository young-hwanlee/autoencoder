{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "autoencoder.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPLN8hEKMmnhnfnWk7uY4io",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/young-hwanlee/autoencoder/blob/master/autoencoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gb-0Vp-ebDlc"
      },
      "source": [
        "!git clone https://github.com/young-hwanlee/autoencoder.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTSZVqEsbVfm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0841a528-cd4b-46ff-a379-dd80b45f9f26"
      },
      "source": [
        "ls -ltr"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 8\n",
            "drwxr-xr-x 1 root root 4096 Mar  5 14:37 \u001b[0m\u001b[01;34msample_data\u001b[0m/\n",
            "drwxr-xr-x 3 root root 4096 Mar 16 05:13 \u001b[01;34mautoencoder\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LwxB_p_lopO8",
        "outputId": "0996e516-6797-4586-f3d9-63788c42a452"
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5RtVH7jbVnd"
      },
      "source": [
        "#%%\r\n",
        "import os\r\n",
        "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\r\n",
        "\r\n",
        "from tqdm import trange\r\n",
        "import tensorflow as tf\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUUX7e0MbVqh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "outputId": "2ef9245e-66e3-4274-858f-db4378fc227d"
      },
      "source": [
        "# from tensorflow.examples.tutorials.mnist import input_data\r\n",
        "# mnist = input_data.read_data_sets(\"/tmp/data/\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-c50d5bb4a85c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexamples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtutorials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmnist\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minput_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmnist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_data_sets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/tmp/data/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.examples'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4idC70PgFP8"
      },
      "source": [
        "# mnist = tf.keras.datasets.mnist.load_data()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBmhF2pIfNgH"
      },
      "source": [
        "## Set up the seed for reproducibility.\r\n",
        "seed = 42\r\n",
        "\r\n",
        "# tf.reset_default_graph()          # It seems like it's only working in the old version.\r\n",
        "# tf.set_random_seed(seed)          # It seems like it's only working in the old version.\r\n",
        "\r\n",
        "tf.compat.v1.reset_default_graph()\r\n",
        "tf.compat.v1.set_random_seed(seed)\r\n",
        "np.random.seed(seed)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JL3kxu0fSR_"
      },
      "source": [
        "## Set up the hyperparameters\r\n",
        "scale_weights = 1e-4\r\n",
        "learning_rate = 1e-1\r\n",
        "n_epochs = 50\r\n",
        "batch_size = 100"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GS57qSyhNcL"
      },
      "source": [
        "#%%\r\n",
        "## [Construction phase]\r\n",
        "n_inputs = 28*28\r\n",
        "n_hidden1 = 256\r\n",
        "n_hidden2 = 256\r\n",
        "\r\n",
        "n_codes = 100\r\n",
        "n_outputs = n_inputs\r\n",
        "\r\n",
        "n_train = 20000\r\n",
        "# n_train = 55000   # over 60,000"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JzfFvkHpg6UL",
        "outputId": "479c0d96-34c7-47b8-a64b-497372aea867"
      },
      "source": [
        "type(mnist)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tuple"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3pxgQpO1haoq",
        "outputId": "696d1263-1df5-478c-ba0d-bbc51dd80784"
      },
      "source": [
        "mnist"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((array([[[0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          ...,\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0]],\n",
              "  \n",
              "         [[0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          ...,\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0]],\n",
              "  \n",
              "         [[0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          ...,\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0]],\n",
              "  \n",
              "         ...,\n",
              "  \n",
              "         [[0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          ...,\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0]],\n",
              "  \n",
              "         [[0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          ...,\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0]],\n",
              "  \n",
              "         [[0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          ...,\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8),\n",
              "  array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)),\n",
              " (array([[[0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          ...,\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0]],\n",
              "  \n",
              "         [[0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          ...,\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0]],\n",
              "  \n",
              "         [[0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          ...,\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0]],\n",
              "  \n",
              "         ...,\n",
              "  \n",
              "         [[0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          ...,\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0]],\n",
              "  \n",
              "         [[0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          ...,\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0]],\n",
              "  \n",
              "         [[0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          ...,\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8),\n",
              "  array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2IjE1Jmmhiaf",
        "outputId": "b7d43974-fef7-4f29-fb0f-fc09c8563b64"
      },
      "source": [
        "len(mnist)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKTkAnihjhTl"
      },
      "source": [
        "# X_train = mnist.train.images[:n_train]   # It seems like it's only working in the old version.\r\n",
        "# X_val = mnist.validation.images          # It seems like it's only working in the old version.\r\n",
        "# X_test = mnist.test.images               # It seems like it's only working in the old version.\r\n",
        "\r\n",
        "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\r\n",
        "X_train = tf.reshape(X_train , [-1 , 784])\r\n",
        "X_test = tf.reshape(X_test , [-1 , 784])"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0KGVmo77kXLW",
        "outputId": "72d8f167-62ec-4913-8327-5c25995da858"
      },
      "source": [
        "# len(X_train[:n_train])\r\n",
        "# len(X_train[n_train:])\r\n",
        "\r\n",
        "X_train[:n_train].shape"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([Dimension(20000), Dimension(784)])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Zmx1alKtF1J",
        "outputId": "e70c17f0-ce9c-4129-ac58-5489787f539e"
      },
      "source": [
        "X_train[-5000:].shape"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([Dimension(5000), Dimension(784)])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqAgf4NSfXcp"
      },
      "source": [
        "X_train = X_train[:n_train]\r\n",
        "X_val = X_train[-5000:]\r\n",
        "\r\n",
        "# X = tf.placeholder(tf.float32, shape=[None, n_inputs], name=\"X\")   # It seems like it's only working in the old version.\r\n",
        "# y = tf.placeholder(tf.float32, shape=[None, n_codes], name=\"y\")    # It seems like it's only working in the old version.\r\n",
        "\r\n",
        "tf.compat.v1.disable_eager_execution()      # In order to run the codes with TensorFlow 2.x\r\n",
        "X = tf.compat.v1.placeholder(tf.float32, shape=[None, n_inputs], name=\"X\")\r\n",
        "y = tf.compat.v1.placeholder(tf.float32, shape=[None, n_codes], name=\"y\")"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJQFfW5elZWv"
      },
      "source": [
        "b1 = tf.Variable(tf.zeros(shape=[n_hidden1]), dtype=tf.float32)\r\n",
        "b2 = tf.Variable(tf.zeros(shape=[n_codes]), dtype=tf.float32)\r\n",
        "b3 = tf.Variable(tf.zeros(shape=[n_hidden2]), dtype=tf.float32)\r\n",
        "b4 = tf.Variable(tf.zeros(shape=[n_inputs]), dtype=tf.float32)\r\n",
        "\r\n",
        "## He initialization (with any variant of ReLU)\r\n",
        "initializer = tf.contrib.layers.variance_scaling_initializer(mode='FAN_AVG')\r\n",
        "W1 = tf.Variable(initializer(shape=[n_inputs, n_hidden1]), dtype=tf.float32, name='W1')\r\n",
        "W2 = tf.Variable(initializer(shape=[n_hidden1, n_codes]), dtype=tf.float32, name='W2')\r\n",
        "W3 = tf.Variable(initializer(shape=[n_codes, n_hidden2]), dtype=tf.float32, name='W3')\r\n",
        "W4 = tf.Variable(initializer(shape=[n_hidden2, n_outputs]), dtype=tf.float32, name='W4')"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPJ97Nopm0NH"
      },
      "source": [
        "with tf.name_scope(\"encoder\"):  # to group related nodes\r\n",
        "    hidden1 = tf.nn.relu(tf.matmul(X, W1) + b1)\r\n",
        "    codes = tf.matmul(hidden1, W2) + b2\r\n",
        "    codes_with_activation_fnc = tf.nn.relu(codes)\r\n",
        "\r\n",
        "with tf.name_scope(\"decoder\"):  # to group related nodes\r\n",
        "    hidden2 = tf.nn.relu(tf.matmul(codes_with_activation_fnc, W3) + b3)\r\n",
        "    X_prime = tf.matmul(hidden2, W4) + b4\r\n",
        "\r\n",
        "with tf.name_scope(\"loss\"):  # to group related nodes\r\n",
        "    reg_loss = tf.reduce_sum(tf.square(W1)) + tf.reduce_sum(tf.square(W2)) \\\r\n",
        "               + tf.reduce_sum(tf.square(W3)) + tf.reduce_sum(tf.square(W4))\r\n",
        "    loss = tf.add(tf.reduce_mean(tf.square(X - X_prime)), scale_weights * reg_loss, name=\"loss\")\r\n",
        "\r\n",
        "with tf.name_scope(\"train\"):  # to group related nodes\r\n",
        "    # optimizer = tf.train.GradientDescentOptimizer(learning_rate)\r\n",
        "    optimizer = tf.train.MomentumOptimizer(learning_rate, momentum=0.9, use_nesterov=True)\r\n",
        "    training_op = optimizer.minimize(loss)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfq5mh0qbVwh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8b4794e8-0d11-40c2-ba71-7412b5a37b5c"
      },
      "source": [
        "#%%\r\n",
        "## [Excution phase]\r\n",
        "init = tf.global_variables_initializer()\r\n",
        "saver = tf.train.Saver()  # to save the trained model parameters to disk\r\n",
        "\r\n",
        "# if cross_entropy_check == \"1\":\r\n",
        "#     acc_train_hist, acc_val_hist = [], []\r\n",
        "loss_train_hist, loss_val_hist = [], []\r\n",
        "\r\n",
        "with tf.Session() as sess:\r\n",
        "    init.run()\r\n",
        "\r\n",
        "    for epoch in trange(n_epochs):\r\n",
        "        for iteration in range(int(np.shape(X_train)[0] // batch_size)):\r\n",
        "            X_batch = X_train[iteration * batch_size:(iteration + 1) * batch_size]\r\n",
        "            sess.run(training_op, feed_dict={X: X_batch.eval()})    # Add \".eval()\" to make it run\r\n",
        "\r\n",
        "            loss_train = loss.eval(feed_dict={X: X_batch.eval()})\r\n",
        "            loss_val = loss.eval(feed_dict={X: X_val.eval()})\r\n",
        "            loss_train_hist.append(loss_train)\r\n",
        "            loss_val_hist.append(loss_val)\r\n",
        "\r\n",
        "            if iteration % 100 == 0:\r\n",
        "                print(\"\\nepoch :\", epoch, \"\\titeration :\", iteration)\r\n",
        "                print(\"loss :\", loss_val)\r\n",
        "\r\n",
        "    X_prime_check = X_prime.eval(feed_dict={X: X_val.eval()})"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "epoch : 0 \titeration : 0\n",
            "loss : 2.1183099e+21\n",
            "\n",
            "epoch : 0 \titeration : 100\n",
            "loss : nan\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  2%|▏         | 1/50 [02:47<2:16:57, 167.71s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "epoch : 1 \titeration : 0\n",
            "loss : nan\n",
            "\n",
            "epoch : 1 \titeration : 100\n",
            "loss : nan\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  4%|▍         | 2/50 [05:38<2:15:00, 168.76s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "epoch : 2 \titeration : 0\n",
            "loss : nan\n",
            "\n",
            "epoch : 2 \titeration : 100\n",
            "loss : nan\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  6%|▌         | 3/50 [08:49<2:17:13, 175.19s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "epoch : 3 \titeration : 0\n",
            "loss : nan\n",
            "\n",
            "epoch : 3 \titeration : 100\n",
            "loss : nan\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  8%|▊         | 4/50 [12:09<2:20:01, 182.65s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "epoch : 4 \titeration : 0\n",
            "loss : nan\n",
            "\n",
            "epoch : 4 \titeration : 100\n",
            "loss : nan\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-829212391bd8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0miteration\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mX_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0miteration\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m    \u001b[0;31m# Add \".eval()\" to make it run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mloss_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m    796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m     \"\"\"\n\u001b[0;32m--> 798\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mexperimental_ref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[0;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   5405\u001b[0m                        \u001b[0;34m\"the tensor's graph is different from the session's \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5406\u001b[0m                        \"graph.\")\n\u001b[0;32m-> 5407\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1180\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1363\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1350\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1441\u001b[0m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[1;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5ID_gE941rc"
      },
      "source": [
        "# ** It seems like the coding is not working well after the version of TensorFlow was upgraded. And I need to modify a lot.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9px6mXmPfdMH"
      },
      "source": [
        "#%%\r\n",
        "## Check the results\r\n",
        "print(\"MSE : \", np.sum(np.square(X_val - X_prime_check))/(np.shape(X_val)[0]*np.shape(X_val)[1]))\r\n",
        "\r\n",
        "plt.figure()\r\n",
        "plt.plot(loss_train_hist)\r\n",
        "plt.plot(loss_val_hist)\r\n",
        "plt.ylabel('loss')\r\n",
        "plt.xlabel('iterations')\r\n",
        "plt.legend(['train', 'validation'], loc='upper right')\r\n",
        "plt.show()\r\n",
        "\r\n",
        "#%%\r\n",
        "n = 10  # how many digits we will display\r\n",
        "plt.figure(figsize=(20, 4))\r\n",
        "for i in range(n):\r\n",
        "    # display original\r\n",
        "    ax = plt.subplot(2, n, i + 1)\r\n",
        "    plt.imshow(X_val[i].reshape(28, 28))\r\n",
        "    plt.gray()\r\n",
        "    ax.get_xaxis().set_visible(False)\r\n",
        "    ax.get_yaxis().set_visible(False)\r\n",
        "\r\n",
        "    # display reconstruction\r\n",
        "    ax = plt.subplot(2, n, i + 1 + n)\r\n",
        "    plt.imshow(X_prime_check[i].reshape(28, 28))\r\n",
        "    plt.gray()\r\n",
        "    ax.get_xaxis().set_visible(False)\r\n",
        "    ax.get_yaxis().set_visible(False)\r\n",
        "\r\n",
        "fig.text(0.475, 0.85, 'Original Figures', va='center')\r\n",
        "fig.text(0.45, 0.425, 'Reconstructed Figures', va='center')\r\n",
        "    \r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}